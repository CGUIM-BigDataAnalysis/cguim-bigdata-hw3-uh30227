---
title: "長庚大學 大數據分析方法 作業三"
output: github_document
---

## 作業說明 （繳交時請直接刪除這個章節）

作業目的：練習初級爬蟲，並將爬蟲結果整理成資料框data.frame

依下列指示，完成網站內文分析：

- 爬取指定網站內容
    - 學號結尾 0,4,8:[Ptt Tech_Job 版](https://www.ptt.cc/bbs/Tech_Job/index.html)
    - 學號結尾 1,5,9:[Ptt NBA 版](https://www.ptt.cc/bbs/NBA/index.html)
    - 學號結尾 2,6:[Ptt LoL 版](https://www.ptt.cc/bbs/LoL/index.html)
    - 學號結尾 3,7:[Ptt movie 版](https://www.ptt.cc/bbs/movie/index.html)
    
- 試著爬出**至少100篇**文章（`30pt`）的**標題**、**推文數**與**作者ID**（各`10pt`）
    - 資料框欄位名稱：
        - **標題**：Title
        - **推文數**：PushNum
        - **作者ID**：Author
    - 一頁只有20篇，該怎麼辦？
        - 提示：使用for + rbind()將分批爬取出的資料結合
        - 範例：dataframeAll<-rbind(dataframe1,dataframe2) 
        - 參考：[6.6 資料組合](http://yijutseng.github.io/DataScienceRBook/manipulation.html#section-6.6)
    
- 將爬取出的資料輸出至Markdown報告中（`10pt`）
    - 使用knitr::kable(資料框物件)整理輸出
    
- 用文字搭配程式碼解釋爬蟲結果 
    - 共爬出幾篇文章標題？（程式碼與文字解釋各`5pt`）
        - dim(), nrow(), str()皆可
    - 哪個作者文章數最多？（程式碼與文字解釋各`5pt`）
        - table()
    - 其他爬蟲結果解釋（`10pt`）
        - 試著找出有趣的現象，不一定要用程式碼搭配解釋，也可只用文字

    

## 網站資料爬取
```{r}
##install.packages("rvest") ##安裝
library(rvest) ##載入
dataframeAll=NULL
for(i in 5289:5299){
url=paste0("http://www.ptt.cc/bbs/movie/index",i,".html",sep='')
PTT_Title = read_html(url) %>% html_nodes(".title") %>% html_text()
PTT_PushNum = read_html(url) %>% html_nodes(".nrec") %>% html_text()
PTT_Author = read_html(url) %>% html_nodes(".author") %>% html_text()
dataframe = data.frame(title = PTT_Title, PushNum=PTT_PushNum, Author=PTT_Author)
dataframeAll<-rbind(dataframeAll,dataframe)
}
```

## 爬蟲結果呈現
```{r}
knitr::kable(
    dataframeAll[1:120,c("title","PushNum","Author")])
```

## 解釋爬蟲結果 
```{r}
##install.packages("jsonlite")
library(jsonlite)
myjson <- toJSON(dataframeAll)
str(dataframeAll)
table(dataframeAll$ Author)
```

(1)總共爬出220 篇文章，裡面共有3個變數:title、PushNum、Author
(2)沒有名字的作者最多，共有15篇沒屬名的文章，有屬名的文章以DantesChen的文章最多，共4篇

```{r}
#這是R Code Chunk
```

解釋解釋解釋解釋

人工結論與解釋解釋解釋解釋解釋解釋解釋
